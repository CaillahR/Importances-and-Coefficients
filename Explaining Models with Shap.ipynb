{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744a0f5e",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d838f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as miss\n",
    "## Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "## Models & evaluation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib,os\n",
    "## setting random state for reproducibility\n",
    "SEED = 321\n",
    "np.random.seed(SEED)\n",
    "## set text displays for sklearn\n",
    "from sklearn import set_config\n",
    "set_config(display='text')\n",
    "## Using pd.set_option to display more columns\n",
    "pd.set_option('display.max_columns',50)\n",
    "## Importing Custom Functions\n",
    "import sys,os\n",
    "import joblib\n",
    "# sys.path.append(os.path.abspath(\"../\"))\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e601ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fav_style = ('ggplot','tableau-colorblind10')\n",
    "fav_context  ={'context':'notebook', 'font_scale':1.2}\n",
    "plt.style.use(fav_style)\n",
    "sns.set_context(**fav_context)\n",
    "plt.rcParams['savefig.transparent'] = False\n",
    "plt.rcParams['savefig.bbox'] = 'tight'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1096c376",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10b2d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression(model, X_train,y_train, X_test, y_test,for_slides=True): \n",
    "    \"\"\"Evaluates a scikit learn regression model using r-squared and RMSE\n",
    "    FOR SLIDES VERS DOES MULTIPLE PRINT STATEMENTS FOR VERTICAL DISPLAY OF INFO\"\"\"\n",
    "    \n",
    "    ## Training Data\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    r2_train = metrics.r2_score(y_train, y_pred_train)\n",
    "    rmse_train = metrics.mean_squared_error(y_train, y_pred_train, \n",
    "                                            squared=False)\n",
    "    mae_train = metrics.mean_absolute_error(y_train, y_pred_train)\n",
    "    \n",
    "\n",
    "    ## Test Data\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    r2_test = metrics.r2_score(y_test, y_pred_test)\n",
    "    rmse_test = metrics.mean_squared_error(y_test, y_pred_test, \n",
    "                                            squared=False)\n",
    "    mae_test = metrics.mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    if for_slides:\n",
    "        df_version =[['Split','R^2','MAE','RMSE']]\n",
    "        df_version.append(['Train',r2_train, mae_train, rmse_train])\n",
    "        df_version.append(['Test',r2_test, mae_test, rmse_test])\n",
    "        df_results = pd.DataFrame(df_version[1:], columns=df_version[0])\n",
    "        df_results = df_results.round(2)\n",
    "        display(df_results.style.hide(axis='index').format(precision=2, thousands=','))\n",
    "        \n",
    "    else: \n",
    "        print(f\"Training Data:\\tR^2 = {r2_train:,.2f}\\tRMSE = {rmse_train:,.2f}\\tMAE = {mae_train:,.2f}\")\n",
    "        print(f\"Test Data:\\tR^2 = {r2_test:,.2f}\\tRMSE = {rmse_test:,.2f}\\tMAE = {mae_test:,.2f}\")\n",
    "\n",
    "def get_coefficients(lin_reg):\n",
    "    coeffs = pd.Series(lin_reg.coef_, index= lin_reg.feature_names_in_)\n",
    "    coeffs.loc['intercept'] = lin_reg.intercept_\n",
    "    return coeffs\n",
    "\n",
    "def plot_coefficients(coeffs, sort_values=True, top_n=None, figsize=(6,4),\n",
    "                     title=\"Linear Regression Coefficients\", xlabel='Coefficient'):\n",
    "    \"\"\"Plots a Series of coefficients as horizotal bar chart, with option to sort\n",
    "    and to only keep top_n coefficients\"\"\"\n",
    "        \n",
    "    if top_n is not None:\n",
    "        top_n = coeffs.abs().rank().sort_values(ascending=False).head(top_n)\n",
    "        coeffs = coeffs.loc[top_n.index]\n",
    "        \n",
    "    if sort_values:\n",
    "        coeffs = coeffs.sort_values()\n",
    "\n",
    "        \n",
    "        \n",
    "    ax = coeffs.plot(kind='barh', figsize=figsize)\n",
    "    ax.axvline(0, color='k')\n",
    "    ax.set(xlabel=xlabel, title=title);\n",
    "    plt.show()\n",
    "    return ax\n",
    "\n",
    "\n",
    "def get_importances(rf_reg):\n",
    "    importances = pd.Series(rf_reg.feature_importances_, index= rf_reg.feature_names_in_)\n",
    "    return importances\n",
    "\n",
    "\n",
    "def plot_importances(importances, sort_values=True, top_n=None, figsize=(6,4),\n",
    "                     title=\"Feature Importance\", xlabel='Importance'):\n",
    "    if sort_values:\n",
    "        importances = importances.sort_values()\n",
    "        \n",
    "    if top_n is not None:\n",
    "        importances = importances.tail(top_n)\n",
    "        \n",
    "        \n",
    "    ax = importances.plot(kind='barh', figsize=figsize)\n",
    "    ax.axvline(0, color='k')\n",
    "    ax.set(xlabel=xlabel, title=title);\n",
    "    plt.show()\n",
    "    return ax\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf96de",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6534e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X_train', 'y_train', 'X_test', 'y_test', 'preprocessor', 'LinearRegression', 'RandomForestRegressor'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = joblib.load('best-models.joblib')\n",
    "loaded.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "166ca32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4776</th>\n",
       "      <td>16.350</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.029565</td>\n",
       "      <td>Household</td>\n",
       "      <td>256.4646</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7510</th>\n",
       "      <td>15.250</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>179.7660</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5828</th>\n",
       "      <td>12.350</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.158716</td>\n",
       "      <td>Meat</td>\n",
       "      <td>157.2946</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5327</th>\n",
       "      <td>7.975</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.014628</td>\n",
       "      <td>Baking Goods</td>\n",
       "      <td>82.3250</td>\n",
       "      <td>2004</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4810</th>\n",
       "      <td>19.350</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016645</td>\n",
       "      <td>Frozen Foods</td>\n",
       "      <td>120.9098</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Item_Weight Item_Fat_Content  Item_Visibility     Item_Type  Item_MRP  \\\n",
       "4776       16.350          Low Fat         0.029565     Household  256.4646   \n",
       "7510       15.250          Regular         0.000000   Snack Foods  179.7660   \n",
       "5828       12.350          Regular         0.158716          Meat  157.2946   \n",
       "5327        7.975          Low Fat         0.014628  Baking Goods   82.3250   \n",
       "4810       19.350          Low Fat         0.016645  Frozen Foods  120.9098   \n",
       "\n",
       "      Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "4776                       2009      Medium               Tier 3   \n",
       "7510                       2009      Medium               Tier 3   \n",
       "5828                       1999      Medium               Tier 1   \n",
       "5327                       2004       Small               Tier 2   \n",
       "4810                       2002         NaN               Tier 2   \n",
       "\n",
       "            Outlet_Type  \n",
       "4776  Supermarket Type2  \n",
       "7510  Supermarket Type2  \n",
       "5828  Supermarket Type1  \n",
       "5327  Supermarket Type1  \n",
       "4810  Supermarket Type1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = loaded['X_train']\n",
    "y_train = loaded['y_train']\n",
    "X_test = loaded['X_test']\n",
    "y_test = loaded['y_test']\n",
    "preprocessor = loaded['preprocessor']\n",
    "lin_model = loaded['LinearRegression']\n",
    "reg_model= loaded['RandomForestRegressor']\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab91bd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caill\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Item_Fat_Content\n",
      "- Item_Type\n",
      "- Outlet_Location_Type\n",
      "- Outlet_Size\n",
      "- Outlet_Type\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- Item_Fat_Content_Regular\n",
      "- Item_Type_Baking Goods\n",
      "- Item_Type_Breads\n",
      "- Item_Type_Breakfast\n",
      "- Item_Type_Canned\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Low Fat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## evaluate the random forest\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mevaluate_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [3], line 6\u001b[0m, in \u001b[0;36mevaluate_regression\u001b[1;34m(model, X_train, y_train, X_test, y_test, for_slides)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"Evaluates a scikit learn regression model using r-squared and RMSE\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mFOR SLIDES VERS DOES MULTIPLE PRINT STATEMENTS FOR VERTICAL DISPLAY OF INFO\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m## Training Data\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m r2_train \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mr2_score(y_train, y_pred_train)\n\u001b[0;32m      8\u001b[0m rmse_train \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mmean_squared_error(y_train, y_pred_train, \n\u001b[0;32m      9\u001b[0m                                         squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:991\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    989\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    990\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 991\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    994\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:605\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    604\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 605\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\sklearn\\utils\\validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    860\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Low Fat'"
     ]
    }
   ],
   "source": [
    "## evaluate the random forest\n",
    "evaluate_regression(reg_model,X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159b19ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_regression(lin_model,X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a482e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get feature names from already-fit preprocessor\n",
    "\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "## Use the preprocessor to transform X_train into X_train_df\n",
    "X_train_df = pd.DataFrame(preprocessor.transform(X_train),\n",
    "                          index=X_train.index,\n",
    "                          columns=feature_names)\n",
    "\n",
    "\n",
    "## Use the preprocessor to transform X_test into X_test_df \n",
    "\n",
    "X_test_df = pd.DataFrame(preprocessor.transform(X_test),\n",
    "                         index=X_test.index,\n",
    "                          columns=feature_names)\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51699c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and init shap\n",
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1441875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking a sample of the training data\n",
    "X_shap = shap.sample(X_train_df,nsamples = 200,random_state=SEED)\n",
    "y_shap = y_train.loc[X_shap.index]\n",
    "\n",
    "# Instantiating a Model Explainer with the model\n",
    "explainer_reg = shap.Explainer(reg_model)\n",
    "\n",
    "## Getting shap values from the explainer\n",
    "shap_values = explainer(X_shap,y_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3078ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, features = X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd42c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the corresponding y-values\n",
    "y_shap = y_train.loc[X_shap.index]\n",
    "y_shap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98088e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking a sample of the training data\n",
    "X_shap = shap.sample(X_train_df,nsamples = 200,random_state=SEED)\n",
    "y_shap = y_train.loc[X_shap.index]\n",
    "\n",
    "# Instantiating a Model Explainer with the model\n",
    "explainer_lin = shap.Explainer(lin_model)\n",
    "\n",
    "## Getting shap values from the explainer\n",
    "shap_values = explainer(X_shap,y_shap)\n",
    "\n",
    "shap.summary_plot(shap_values, features = X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea7911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb5b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ecaec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8273b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d460a3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052acc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get feature names from already-fit preprocessor\n",
    "\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "## Use the preprocessor to transform X_train into X_train_df\n",
    "X_train_df = pd.DataFrame(preprocessor.transform(X_train),\n",
    "                          index=X_train.index,\n",
    "                          columns=feature_names)\n",
    "\n",
    "\n",
    "## Use the preprocessor to transform X_test into X_test_df \n",
    "\n",
    "X_test_df = pd.DataFrame(preprocessor.transform(X_test),\n",
    "                         index=X_test.index,\n",
    "                          columns=feature_names)\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd84af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use our evaluate_regression function to evalaute the linear regression\n",
    "evaluate_regression(lin_model, X_train_df, y_train, X_test_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab79f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e697b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9fbfa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c91ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e0ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d2a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce85720e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37004f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf89ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ea147",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit random forest\n",
    "rf_clf = RandomForestClassifier()#class_weight='balanced')\n",
    "rf_clf.fit(X_train_df,y_train)\n",
    "evaluate_classification(rf_clf,X_train_df,y_train, X_test_df,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classification(reg_model,X_train_df,y_train, X_test_df,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e6be77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bc20f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35887709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405dfce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6010837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2672b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
